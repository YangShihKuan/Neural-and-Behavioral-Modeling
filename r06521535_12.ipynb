{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural & Behavioral Modeling - Week 12 (Exercises)\n",
    "by 楊士寬 (r06521535@ntu.edu.tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade PyTorch to 0.4.0 if necessary:\n",
    "! conda install -y pytorch-cpu torchvision-cpu -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True \n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import *\n",
    "from IPython.display import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 0.4.0\n",
      "No GPU\n"
     ]
    }
   ],
   "source": [
    "# Check GPU status:\n",
    "import torch as t\n",
    "print('PyTorch version:',t.__version__)\n",
    "use_cuda=t.cuda.is_available()\n",
    "if(use_cuda):\n",
    "    for i in range(t.cuda.device_count()):\n",
    "        print('Device ',i,':',t.cuda.get_device_name(i))\n",
    "    print('Current: Device ',t.cuda.current_device())\n",
    "    t.backends.cudnn.benchmark = True \n",
    "    device = t.device(\"cuda\")\n",
    "else:\n",
    "    device = t.device(\"cpu\")\n",
    "    print('No GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Fair Performance Evaluation (5 points)\n",
    "We often compare and assess performances of different model architectures/parameters/hyperparameters. Note that the results are differnt even if you re-run exactly the same code block. This is primarily due to a non-fixed random number seed. Please:\n",
    "\n",
    "(1) run the section 1.2 TEN times and report (a) min, (b) max, (c) mean, & (d) standard deviation of the TESTING accuracies. (3 points)\n",
    "\n",
    "(2) try to fix the random number seeds in numpy & pytorch to see if you can obtain the same results every time in the section 1.2. (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset:\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "train_set = CIFAR10(root='.', train=True, transform=transforms.ToTensor())\n",
    "train_data = t.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_set = CIFAR10(root='.', train=False, transform=transforms.ToTensor())\n",
    "test_data = t.utils.data.DataLoader(train_set, batch_size=1000, shuffle=True)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model:\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__() # = nn.Module.__init__(self)\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) # in, out, kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
    "        self.fc1   = nn.Linear(16*5*5, 120) \n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "    def forward(self, x): # functional expressions\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) \n",
    "        x = x.view(x.size()[0], -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x\n",
    "lenet = Net()\n",
    "lenet = lenet.to(device)\n",
    "loss_fn = t.nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(lenet.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : 0.4375\n",
      "epoch  1 : 0.6875\n",
      "test : 0.616\n"
     ]
    }
   ],
   "source": [
    "# Training:\n",
    "\n",
    "for e in range(2):\n",
    "    for i, (X_train, Y_train) in enumerate(train_data, 0):\n",
    "        X_train,Y_train=X_train.to(device),Y_train.to(device)\n",
    "        Y_pred = lenet(X_train)\n",
    "        loss = loss_fn(Y_pred, Y_train)\n",
    "        lenet.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "        Y_pred = lenet(X_train)\n",
    "        Y_pred = t.max(Y_pred,1)[1]\n",
    "    print('epoch ',e,':',(Y_pred==Y_train).sum().item()/Y_train.shape[0])\n",
    "    \n",
    "# Testing on a batch:\n",
    "dataiter = iter(test_data)\n",
    "X_test, Y_test = dataiter.next() # returning a batch\n",
    "X_test,Y_test=X_test.to(device),Y_test.to(device)\n",
    "with t.no_grad():\n",
    "    Y_pred = lenet(X_test)\n",
    "    Y_pred = t.max(Y_pred,1)[1]\n",
    "    print('test :',(Y_pred==Y_test).sum().item()/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Your answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a76b4eac3781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-64246cd23472>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# functional expressions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_result = [] \n",
    "for e in range(2):\n",
    "    for i, (X_train, Y_train) in enumerate(train_data, 0):\n",
    "        X_train,Y_train=X_train.to(device),Y_train.to(device)\n",
    "        Y_pred = lenet(X_train)\n",
    "        loss = loss_fn(Y_pred, Y_train)\n",
    "        lenet.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "        Y_pred = lenet(X_train)\n",
    "        Y_pred = t.max(Y_pred,1)[1]\n",
    "    print('epoch ',e,':',(Y_pred==Y_train).sum().item()/Y_train.shape[0])\n",
    "\n",
    "# Testing on a batch:\n",
    "dataiter = iter(test_data)\n",
    "X_test, Y_test = dataiter.next() # returning a batch\n",
    "X_test,Y_test=X_test.to(device),Y_test.to(device)\n",
    "with t.no_grad():\n",
    "    Y_pred = lenet(X_test)\n",
    "    Y_pred = t.max(Y_pred,1)[1]\n",
    "    print('test :',(Y_pred==Y_test).sum().item()/Y_test.shape[0])\n",
    "\n",
    "test_result.append((Y_pred==Y_test).sum().item()/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) (a) min, (b) max, (c) mean, & (d) standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a) min : 0.532\n",
      "(b) max : 0.742\n",
      "(c) mean : 0.6626000000000001\n",
      "(d) standard deviation : 0.06741691182485296\n"
     ]
    }
   ],
   "source": [
    "test_result = [0.532, 0.571, 0.635, 0.635, 0.698, 0.7, 0.651, 0.727, 0.735, 0.742]\n",
    "print (\"(a) min :\" , min(test_result))\n",
    "print (\"(b) max :\" , max(test_result))\n",
    "print (\"(c) mean :\", np.mean(test_result))\n",
    "print (\"(d) standard deviation :\",np.std(test_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) fix the random number seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff646ccf750>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "t.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-703796bfe7c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mlenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_420/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(2):\n",
    "    for i, (X_train, Y_train) in enumerate(train_data, 0):\n",
    "        X_train,Y_train=X_train.to(device),Y_train.to(device)\n",
    "        Y_pred = lenet(X_train)\n",
    "        loss = loss_fn(Y_pred, Y_train)\n",
    "        lenet.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "        Y_pred = lenet(X_train)\n",
    "        Y_pred = t.max(Y_pred,1)[1]\n",
    "    print('epoch ',e,':',(Y_pred==Y_train).sum().item()/Y_train.shape[0])\n",
    "    \n",
    "# Testing on a batch:\n",
    "dataiter = iter(test_data)\n",
    "X_test, Y_test = dataiter.next() # returning a batch\n",
    "X_test,Y_test=X_test.to(device),Y_test.to(device)\n",
    "with t.no_grad():\n",
    "    Y_pred = lenet(X_test)\n",
    "    Y_pred = t.max(Y_pred,1)[1]\n",
    "    print('test :',(Y_pred==Y_test).sum().item()/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Universal Approximation Theorem (5 points)\n",
    "\n",
    "Please FAIRLY evaluate whether a deep network learns XOR more efficiently than a shallow network with the same number of model parameters. Please discuss why in either case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 XOR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d3cd734a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N=1000 # samples per cluster\n",
    "XY=t.tensor([[5,5],[5,10],[10,5],[10,10]],dtype=t.float32) # 4 cluster centers\n",
    "Z=t.tensor([0,1,1,0]) # category labels\n",
    "t.cat([t.randn(2,1)+XY[0,0],t.randn(2,1)+XY[0,1]],1)\n",
    "xy,z=t.zeros(4*N,2),t.zeros(4*N,dtype=t.int64)\n",
    "for i in range(4):\n",
    "    xy[i*N:(i+1)*N,]=t.rand(N,2)+XY[i,]\n",
    "    z[i*N:(i+1)*N]=Z[i]\n",
    "xy_np=xy.numpy()\n",
    "z_np=z.numpy().astype(int)\n",
    "cmap=np.array([[1,0,0],[0,1,0]])\n",
    "scatter(xy_np[:,0],xy_np[:,1],color=cmap[z_np]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 A shallow net with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : 0.515\n",
      "epoch  1 : 0.542\n",
      "epoch  2 : 0.63275\n",
      "epoch  3 : 0.75\n",
      "epoch  4 : 0.75\n",
      "epoch  5 : 0.75\n",
      "epoch  6 : 0.75\n",
      "epoch  7 : 0.75\n",
      "epoch  8 : 0.75\n",
      "epoch  9 : 0.75\n",
      "epoch  10 : 0.75\n",
      "epoch  11 : 0.75\n",
      "epoch  12 : 0.75\n",
      "epoch  13 : 0.75\n",
      "epoch  14 : 0.75\n",
      "epoch  15 : 0.75\n",
      "epoch  16 : 0.75\n",
      "epoch  17 : 0.75\n",
      "epoch  18 : 0.75\n",
      "epoch  19 : 0.75\n",
      "epoch  20 : 0.75\n",
      "epoch  21 : 0.75\n",
      "epoch  22 : 0.76975\n",
      "epoch  23 : 0.8205\n",
      "epoch  24 : 0.869\n",
      "epoch  25 : 0.89925\n",
      "epoch  26 : 0.91975\n",
      "epoch  27 : 0.9405\n",
      "epoch  28 : 0.95725\n",
      "epoch  29 : 0.9715\n",
      "epoch  30 : 0.9825\n",
      "epoch  31 : 0.99025\n",
      "epoch  32 : 0.99525\n",
      "epoch  33 : 0.99875\n",
      "epoch  34 : 1.0\n",
      "epoch  35 : 1.0\n",
      "epoch  36 : 1.0\n",
      "epoch  37 : 1.0\n",
      "epoch  38 : 1.0\n",
      "epoch  39 : 1.0\n",
      "epoch  40 : 1.0\n",
      "epoch  41 : 1.0\n",
      "epoch  42 : 1.0\n",
      "epoch  43 : 1.0\n",
      "epoch  44 : 1.0\n",
      "epoch  45 : 1.0\n",
      "epoch  46 : 1.0\n",
      "epoch  47 : 1.0\n",
      "epoch  48 : 1.0\n",
      "epoch  49 : 1.0\n",
      "epoch  50 : 1.0\n",
      "epoch  51 : 1.0\n",
      "epoch  52 : 1.0\n",
      "epoch  53 : 1.0\n",
      "epoch  54 : 1.0\n",
      "epoch  55 : 1.0\n",
      "epoch  56 : 1.0\n",
      "epoch  57 : 1.0\n",
      "epoch  58 : 1.0\n",
      "epoch  59 : 1.0\n",
      "epoch  60 : 1.0\n",
      "epoch  61 : 1.0\n",
      "epoch  62 : 1.0\n",
      "epoch  63 : 1.0\n",
      "epoch  64 : 1.0\n",
      "epoch  65 : 1.0\n",
      "epoch  66 : 1.0\n",
      "epoch  67 : 1.0\n",
      "epoch  68 : 1.0\n",
      "epoch  69 : 1.0\n",
      "epoch  70 : 1.0\n",
      "epoch  71 : 1.0\n",
      "epoch  72 : 1.0\n",
      "epoch  73 : 1.0\n",
      "epoch  74 : 1.0\n",
      "epoch  75 : 1.0\n",
      "epoch  76 : 1.0\n",
      "epoch  77 : 1.0\n",
      "epoch  78 : 1.0\n",
      "epoch  79 : 1.0\n",
      "epoch  80 : 1.0\n",
      "epoch  81 : 1.0\n",
      "epoch  82 : 1.0\n",
      "epoch  83 : 1.0\n",
      "epoch  84 : 1.0\n",
      "epoch  85 : 1.0\n",
      "epoch  86 : 1.0\n",
      "epoch  87 : 1.0\n",
      "epoch  88 : 1.0\n",
      "epoch  89 : 1.0\n",
      "epoch  90 : 1.0\n",
      "epoch  91 : 1.0\n",
      "epoch  92 : 1.0\n",
      "epoch  93 : 1.0\n",
      "epoch  94 : 1.0\n",
      "epoch  95 : 1.0\n",
      "epoch  96 : 1.0\n",
      "epoch  97 : 1.0\n",
      "epoch  98 : 1.0\n",
      "epoch  99 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Number of free parameters: 2*H+H*2=70\n",
    "\n",
    "H=35 # number of hidden units\n",
    "model = t.nn.Sequential(\n",
    "    t.nn.Linear(2, H, bias=False),\n",
    "    t.nn.BatchNorm1d(H),\n",
    "    t.nn.ReLU(),\n",
    "    t.nn.Linear(H, 2, bias=False),\n",
    "    t.nn.Softmax(dim=1)\n",
    ")\n",
    "loss_fn = t.nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(model.parameters())\n",
    "\n",
    "for i in range(100):\n",
    "    z_pred = model(xy)\n",
    "    loss = loss_fn(z_pred,z)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    z_pred = model(xy) \n",
    "    z_pred = t.max(z_pred,1)[1]\n",
    "    print('epoch ',i,':',(z_pred==z).sum().item()/xy.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 A \"deep\" net with three hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 : 0.0955\n",
      "epoch  1 : 0.175\n",
      "epoch  2 : 0.33825\n",
      "epoch  3 : 0.40275\n",
      "epoch  4 : 0.4235\n",
      "epoch  5 : 0.43975\n",
      "epoch  6 : 0.45225\n",
      "epoch  7 : 0.46675\n",
      "epoch  8 : 0.485\n",
      "epoch  9 : 0.499\n",
      "epoch  10 : 0.51625\n",
      "epoch  11 : 0.53425\n",
      "epoch  12 : 0.55375\n",
      "epoch  13 : 0.5725\n",
      "epoch  14 : 0.58775\n",
      "epoch  15 : 0.60525\n",
      "epoch  16 : 0.622\n",
      "epoch  17 : 0.6425\n",
      "epoch  18 : 0.66\n",
      "epoch  19 : 0.68\n",
      "epoch  20 : 0.701\n",
      "epoch  21 : 0.72025\n",
      "epoch  22 : 0.7345\n",
      "epoch  23 : 0.74175\n",
      "epoch  24 : 0.749\n",
      "epoch  25 : 0.75\n",
      "epoch  26 : 0.75\n",
      "epoch  27 : 0.75\n",
      "epoch  28 : 0.75\n",
      "epoch  29 : 0.75\n",
      "epoch  30 : 0.75\n",
      "epoch  31 : 0.75\n",
      "epoch  32 : 0.75\n",
      "epoch  33 : 0.75\n",
      "epoch  34 : 0.75\n",
      "epoch  35 : 0.75\n",
      "epoch  36 : 0.75\n",
      "epoch  37 : 0.75\n",
      "epoch  38 : 0.75\n",
      "epoch  39 : 0.75\n",
      "epoch  40 : 0.75\n",
      "epoch  41 : 0.75\n",
      "epoch  42 : 0.75\n",
      "epoch  43 : 0.75\n",
      "epoch  44 : 0.75\n",
      "epoch  45 : 0.75\n",
      "epoch  46 : 0.75\n",
      "epoch  47 : 0.75\n",
      "epoch  48 : 0.75\n",
      "epoch  49 : 0.75\n",
      "epoch  50 : 0.75\n",
      "epoch  51 : 0.75\n",
      "epoch  52 : 0.75\n",
      "epoch  53 : 0.7505\n",
      "epoch  54 : 0.7515\n",
      "epoch  55 : 0.753\n",
      "epoch  56 : 0.75625\n",
      "epoch  57 : 0.759\n",
      "epoch  58 : 0.76075\n",
      "epoch  59 : 0.76325\n",
      "epoch  60 : 0.76625\n",
      "epoch  61 : 0.771\n",
      "epoch  62 : 0.775\n",
      "epoch  63 : 0.77875\n",
      "epoch  64 : 0.78225\n",
      "epoch  65 : 0.787\n",
      "epoch  66 : 0.79\n",
      "epoch  67 : 0.794\n",
      "epoch  68 : 0.7975\n",
      "epoch  69 : 0.80175\n",
      "epoch  70 : 0.806\n",
      "epoch  71 : 0.81175\n",
      "epoch  72 : 0.819\n",
      "epoch  73 : 0.82475\n",
      "epoch  74 : 0.8305\n",
      "epoch  75 : 0.84\n",
      "epoch  76 : 0.849\n",
      "epoch  77 : 0.85725\n",
      "epoch  78 : 0.8645\n",
      "epoch  79 : 0.87325\n",
      "epoch  80 : 0.88475\n",
      "epoch  81 : 0.8965\n",
      "epoch  82 : 0.90775\n",
      "epoch  83 : 0.91975\n",
      "epoch  84 : 0.92975\n",
      "epoch  85 : 0.943\n",
      "epoch  86 : 0.95525\n",
      "epoch  87 : 0.973\n",
      "epoch  88 : 0.9885\n",
      "epoch  89 : 0.99725\n",
      "epoch  90 : 1.0\n",
      "epoch  91 : 1.0\n",
      "epoch  92 : 1.0\n",
      "epoch  93 : 1.0\n",
      "epoch  94 : 1.0\n",
      "epoch  95 : 1.0\n",
      "epoch  96 : 1.0\n",
      "epoch  97 : 1.0\n",
      "epoch  98 : 1.0\n",
      "epoch  99 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Number of free parameters: 2*H+H*H+H*H+H*2=70\n",
    "\n",
    "H=5 # number of hidden units\n",
    "model = t.nn.Sequential(\n",
    "    t.nn.Linear(2, H, bias=False),\n",
    "    t.nn.BatchNorm1d(H),\n",
    "    t.nn.ReLU(),\n",
    "    t.nn.Linear(H, H,bias=False),\n",
    "    t.nn.BatchNorm1d(H),\n",
    "    t.nn.ReLU(),\n",
    "    t.nn.Linear(H, H, bias=False),\n",
    "    t.nn.BatchNorm1d(H),\n",
    "    t.nn.ReLU(),\n",
    "    t.nn.Linear(H, 2, bias=False),\n",
    "    t.nn.Softmax(dim=1)\n",
    ")\n",
    "loss_fn = t.nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(model.parameters())\n",
    "\n",
    "for i in range(100):\n",
    "    z_pred = model(xy)\n",
    "    loss = loss_fn(z_pred,z)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    z_pred = model(xy) \n",
    "    z_pred = t.max(z_pred,1)[1]\n",
    "    print('epoch ',i,':',(z_pred==z).sum().item()/xy.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Your answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為多層次會把問題先簡化過濾後在處理，再進去下一層，每一層都被訓練來達成某一個小目標，將一個複雜的問題分段解決，單層一次就想解決比較複雜的問題，效率會比較差，我想這是這是\"deep net work\"比較有效率的原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
